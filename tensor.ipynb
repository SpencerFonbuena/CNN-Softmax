{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download The Dependencies or however you spell that. Dependencys, Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 07:36:16.435014: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import csv \n",
    "import mplfinance as mpf\n",
    "import pandas as pd\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CANDLES = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data from the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "df = pd.read_csv('/Users/spencerfonbuena/Desktop/ES.txt', header = None, names = ['Date', 'open', 'high', 'low', \n",
    "    'close', 'volume'], sep=',',index_col=0,parse_dates=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2005-09-06 16:30:00    1096.25\n",
       "2005-09-06 16:35:00    1096.00\n",
       "2005-09-06 16:40:00    1095.75\n",
       "2005-09-06 16:45:00    1096.00\n",
       "2005-09-06 16:50:00    1096.25\n",
       "                        ...   \n",
       "2022-08-12 16:35:00    4281.50\n",
       "2022-08-12 16:40:00    4281.50\n",
       "2022-08-12 16:45:00    4281.50\n",
       "2022-08-12 16:50:00    4281.50\n",
       "2022-08-12 16:55:00    4280.75\n",
       "Name: close, Length: 1191027, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take the CSV data, and turn it into images\n",
    "\n",
    "### This also takes the images and seperates them into different folders which represent each class we are trying to predict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize number of candles to be shown on graph\n",
    "A = 500000\n",
    "B = A + NUM_CANDLES\n",
    "C = 0\n",
    "label_yhat = []\n",
    "for i in range(0, 100):\n",
    "\n",
    "    #store the number of candles you want shown on the graph\n",
    "    storage = df.iloc[A:B]\n",
    "    #create the graph\n",
    "    mc = mpf.make_marketcolors(up='g',down='r')\n",
    "    s  = mpf.make_mpf_style(marketcolors=mc)\n",
    "\n",
    "\n",
    "    #find 1 percent and 2 percent above and below\n",
    "    one_low = df['close'][B] * .99\n",
    "    two_low = df['close'][B] * .98\n",
    "    one_high = df['close'][B] * 1.01\n",
    "    two_high = df['close'][B] * 1.02\n",
    "    #initialize the label counter\n",
    "    label_counter = B\n",
    "\n",
    "    #this is to make sure that once it either enters the \"gone up by one percent\" or \"gone down by 1 percent\"\n",
    "    #it doesn't enter the other while loops\n",
    "    pathway = 0\n",
    "    #look for the instance when the price increases or decreases by 1 percent\n",
    "    while df['low'][label_counter] >= one_low and df['high'][label_counter] <= one_high:\n",
    "        label_counter += 1\n",
    "\n",
    "    #If the price moved up 1 pecent first, this while loop will trigger and check if it is a two to one, or a one to one trade\n",
    "    while df['low'][label_counter] >= one_low and df['high'][label_counter] <= two_high:\n",
    "        label_counter += 1\n",
    "        pathway = 1\n",
    "    #Check if price has increased two percent\n",
    "    if df['high'][label_counter] >= two_high and pathway == 1:\n",
    "        label_yhat.append('twoup')\n",
    "    #check if price has reversed back down to the one percent marker\n",
    "    elif df['low'][label_counter] <= one_low and pathway == 1:\n",
    "        label_yhat.append('oneup')\n",
    "    \n",
    "    #if the price moved down 1 pecent first, this will check if it is a two to one, or a one to one trade\n",
    "    while df['high'][label_counter] <= one_high and df['low'][label_counter] >= two_low and pathway != 1:\n",
    "        label_counter += 1\n",
    "        pathway = 2\n",
    "    #check if the price has continued down two percent\n",
    "    if df['low'][label_counter] <= two_low and pathway == 2:\n",
    "        label_yhat.append('twodown')\n",
    "    #check if price reversed back up to the 1 percent above marker\n",
    "    elif df['high'][label_counter] >= one_high and pathway == 2:\n",
    "        label_yhat.append('onedown')\n",
    "\n",
    "    #converts the list of labels into a numpy array\n",
    "    yhat = np.array(label_yhat)\n",
    "\n",
    "    # seperates the photos into classifications\n",
    "    if yhat[C] == 'twoup':\n",
    "        file_path = '/Users/spencerfonbuena/Documents/Images/two_up/' + str(i) + '.png'\n",
    "        mpf.plot(storage,type='candle',savefig=file_path , warn_too_much_data = 10000000, style = s, volume=True)\n",
    "        #this resized the image to be a 512x512 resolution imgae\n",
    "        sized_image = Image.open('/Users/spencerfonbuena/Documents/Images/two_up/' + str(i) + '.png').crop((177,40,689,552)).save('/Users/spencerfonbuena/Documents/Images/two_up/' + str(i) + '.png')\n",
    "    elif yhat[C] == 'oneup':\n",
    "        file_path = '/Users/spencerfonbuena/Documents/Images/one_up/' + str(i) + '.png'\n",
    "        mpf.plot(storage,type='candle',savefig=file_path , warn_too_much_data = 10000000, style = s, volume=True)\n",
    "        #this resized the image to be a 512x512 resolution imgae\n",
    "        sized_image = Image.open('/Users/spencerfonbuena/Documents/Images/one_up/' + str(i) + '.png').crop((177,40,689,552)).save('/Users/spencerfonbuena/Documents/Images/one_up/' + str(i) + '.png')\n",
    "    elif yhat[C] == 'onedown':\n",
    "        file_path = '/Users/spencerfonbuena/Documents/Images/one_down/' + str(i) + '.png'\n",
    "        mpf.plot(storage,type='candle',savefig=file_path , warn_too_much_data = 10000000, style = s, volume=True)\n",
    "        #this resized the image to be a 512x512 resolution imgae\n",
    "        sized_image = Image.open('/Users/spencerfonbuena/Documents/Images/one_down/' + str(i) + '.png').crop((177,40,689,552)).save('/Users/spencerfonbuena/Documents/Images/one_down/' + str(i) + '.png')\n",
    "    elif yhat[C] == 'twodown':\n",
    "        file_path = '/Users/spencerfonbuena/Documents/Images/two_down/' + str(i) + '.png'\n",
    "        mpf.plot(storage,type='candle',savefig=file_path , warn_too_much_data = 10000000, style = s, volume=True)\n",
    "        #this resized the image to be a 512x512 resolution imgae\n",
    "        sized_image = Image.open('/Users/spencerfonbuena/Documents/Images/two_down/' + str(i) + '.png').crop((177,40,689,552)).save('/Users/spencerfonbuena/Documents/Images/two_down/' + str(i) + '.png')\n",
    "        \n",
    "    #increment the graph by one 15 minute interval \n",
    "    A += 1\n",
    "    B += 1\n",
    "    C += 1\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use TS.Keras to label the data\n",
    "## This will also load the data into our data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 files belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 05:08:48.337117: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('/Users/spencerfonbuena/Documents/Images', image_size=(512,512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process the Data\n",
    "I am fairly certain that this simply makes us able to access our data pipeline. It alos normalizes the data. Be careful however not to run this twice. If you do, it will divide your RGB pixel values by 255 twice, and then you will end up with a black screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x, y: (x/255, y))\n",
    "data_iterator = data.as_numpy_iterator()\n",
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into train, dev, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data) * .90) # 95 percent training set\n",
    "dev_size = int(len(data) * .05) # 2.5 percent development set\n",
    "test_size = int(len(data) * .05) # 2.5 percent test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_size)\n",
    "development = data.skip(train_size).take(dev_size)\n",
    "test = data.skip(train_size + dev_size).take(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Propogation Model (More or Less) \n",
    "## VGG16 with 528 Million parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                                                                                            #Output Shapes\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=1 ,padding='same', activation='relu', input_shape=(512,512,3) )) #(512,512,64)\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=1 ,padding='same', activation='relu')) #(512,512,64)\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2)) #(256,256,64)\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=1 ,padding='same', activation='relu')) #(256,256,128)\n",
    "model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=1 ,padding='same', activation='relu')) #(256,256,128)\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2)) #(128,128,128)\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=1 ,padding='same', activation='relu')) #(128,128, 256)\n",
    "model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=1 ,padding='same', activation='relu')) #(128,128,256)\n",
    "model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=1 ,padding='same', activation='relu')) #(128,128,256)\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2)) #(64,64,256)\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), strides=1 ,padding='same', activation='relu')) #(64,64,512)\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2)) #(32, 32, 512)\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), strides=1 ,padding='same', activation='relu')) #(32,32,512)\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2)) #(16,16,512)\n",
    "\n",
    "model.add(tf.keras.layers.Flatten()) #(0, 131072)\n",
    "model.add(tf.keras.layers.Dense(units=4096, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units=4096, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units=4, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Propogation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss= tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = '/Users/spencerfonbuena/Documents/logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/3 [===================>..........] - ETA: 1:52 - loss: 0.6810 - accuracy: 0.8906"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train, epochs=10, validation_data=development, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de97fb2f739c35e802b623de1072333786e0760d2e9d92790d1f075733a7fc1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
